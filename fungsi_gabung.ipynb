{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbMdtwWA07qv",
        "outputId": "cfb771c2-9a9a-472c-be56-867cd80c60f5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (3.1.43)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 7)) (1.25.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 8)) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 9)) (10.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.32.0 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 13)) (1.11.4)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 16)) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 17)) (4.66.4)\n",
            "Requirement already satisfied: ultralytics>=8.0.232 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (8.2.29)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 27)) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 28)) (0.13.1)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 42)) (67.7.2)\n",
            "Requirement already satisfied: wheel>=0.38.0 in /usr/local/lib/python3.10/dist-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 50)) (0.43.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (4.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (2024.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.5.40)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.232->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: ultralytics-thop>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.232->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (0.2.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 27)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 27)) (2024.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (5.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IopPQibw0_o0",
        "outputId": "791a9310-3f2d-4161-8815-47922349c467"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dill\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill\n",
            "Successfully installed dill-0.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ini tidak dipakai untuk capstone, hanya untuk keperluan testing\n",
        "#digunakan untuk membentuk frames dari sebuah video\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def video_to_frames(video_path, output_folder):\n",
        "    # Membuat folder output jika belum ada\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Membuka video file\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open video.\")\n",
        "        return\n",
        "\n",
        "    # Inisialisasi counter frame\n",
        "    frame_count = 0\n",
        "\n",
        "    while True:\n",
        "        # Membaca frame dari video\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Menyimpan frame ke folder output\n",
        "        frame_filename = os.path.join(output_folder, f'frame_{frame_count:04d}.jpg')\n",
        "        cv2.imwrite(frame_filename, frame)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    # Release video capture object\n",
        "    cap.release()\n",
        "    print(f\"Total frames extracted: {frame_count}\")\n",
        "\n",
        "# Contoh penggunaan fungsi\n",
        "video_path = '/content/WIN_20240603_15_00_18_Pro.mp4'  # Path ke file video Anda\n",
        "output_folder = '/content/frames'  # Path ke folder output Anda\n",
        "\n",
        "video_to_frames(video_path, output_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DP5B1UhbAcH",
        "outputId": "e1c0b56c-58d4-4d86-f871-d08befbc926c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total frames extracted: 425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ini yang terpakai untuk capstone\n",
        "# deteksi objek dengan input frame, hasil processing disimpan ke folder baru\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def detect_objects_from_folder(model_path, folder_path, object_labels, fps):\n",
        "    # Load frames from the folder in one line\n",
        "    frames = [cv2.imread(os.path.join(folder_path, filename)) for filename in sorted(os.listdir(folder_path)) if filename.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    # Load YOLOv5 model\n",
        "    model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path, force_reload=True)\n",
        "\n",
        "    # Variables to track detected object and its duration\n",
        "    detected_object = None\n",
        "    start_time = None\n",
        "    total_duration = {label: 0 for label in object_labels}\n",
        "\n",
        "    processed_frames = []\n",
        "\n",
        "    # Process each frame\n",
        "    for frame_count, frame in enumerate(frames):\n",
        "        # Perform object detection on the frame\n",
        "        results = model(frame)\n",
        "\n",
        "        # Flags to indicate if any object is detected in the current frame\n",
        "        object_detected = {label: False for label in object_labels}\n",
        "\n",
        "        # Draw bounding boxes on the frame\n",
        "        for detection in results.xyxy[0]:\n",
        "            x1, y1, x2, y2, confidence, class_idx = detection\n",
        "            label = model.names[int(class_idx)]\n",
        "\n",
        "            # Check if the label is in the object_labels list\n",
        "            if label in object_labels:\n",
        "                # Convert coordinates to integers\n",
        "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "\n",
        "                # Draw bounding box\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "                # Add label and confidence score\n",
        "                text = f'{label}: {confidence:.2f}'\n",
        "                cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "                # Track detected objects\n",
        "                object_detected[label] = True\n",
        "\n",
        "        # Update detected objects and their durations\n",
        "        for label in object_labels:\n",
        "            if object_detected[label]:\n",
        "                if detected_object != label:\n",
        "                    detected_object = label\n",
        "                    start_time = frame_count  # Use frame count instead of timestamp for simplicity\n",
        "            else:\n",
        "                if detected_object == label:\n",
        "                    end_time = frame_count\n",
        "                    duration = end_time - start_time\n",
        "                    total_duration[label] += duration\n",
        "                    print(f'{label} detected for {duration} frames')\n",
        "                    detected_object = None\n",
        "\n",
        "        # Append processed frame to list\n",
        "        processed_frames.append(frame)\n",
        "\n",
        "    # Convert frame duration to seconds\n",
        "    total_duration_seconds = {label: duration / fps for label, duration in total_duration.items()}\n",
        "\n",
        "    # Print total duration of the detected objects in seconds\n",
        "    for label, duration in total_duration_seconds.items():\n",
        "        print(f'Total duration of {label}: {duration:.2f} seconds')\n",
        "\n",
        "    # Save processed frames to folder\n",
        "    processed_frames_dir = '/content/processed_framesfixbgtplis'\n",
        "    if not os.path.exists(processed_frames_dir):\n",
        "        os.makedirs(processed_frames_dir)\n",
        "\n",
        "    for i, frame in enumerate(processed_frames):\n",
        "        cv2.imwrite(f'{processed_frames_dir}/frame_{i:04d}.jpg', frame)\n",
        "\n",
        "    # Release the OpenCV window\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    return processed_frames, total_duration_seconds\n",
        "\n",
        "\n",
        "# Example usage\n",
        "model_path = '/content/weightsbest (1).pt'  # Path to YOLOv5 model\n",
        "folder_path = '/content/frames'  # Path to folder containing frames\n",
        "object_labels = ['bottle', 'cigarette', 'phone', 'smoke', 'vape']  # Object labels to detect\n",
        "fps = 30  # Frame rate of the original video\n",
        "\n",
        "processed_frames, durations = detect_objects_from_folder(model_path, folder_path, object_labels, fps)\n",
        "\n",
        "print('Durations for each object:')\n",
        "for label, duration in durations.items():\n",
        "    print(f'{label}: {duration:.2f} seconds')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEBKf1h-dDFn",
        "outputId": "75770637-c9db-4a64-8148-5b1adc533f28"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 🚀 2024-6-9 Python-3.10.12 torch-2.3.0+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phone detected for 20 frames\n",
            "phone detected for 1 frames\n",
            "phone detected for 1 frames\n",
            "bottle detected for 1 frames\n",
            "bottle detected for 4 frames\n",
            "bottle detected for 1 frames\n",
            "bottle detected for 10 frames\n",
            "bottle detected for 3 frames\n",
            "cigarette detected for 1 frames\n",
            "bottle detected for 13 frames\n",
            "bottle detected for 1 frames\n",
            "bottle detected for 2 frames\n",
            "bottle detected for 1 frames\n",
            "cigarette detected for 1 frames\n",
            "cigarette detected for 1 frames\n",
            "bottle detected for 20 frames\n",
            "bottle detected for 2 frames\n",
            "bottle detected for 1 frames\n",
            "bottle detected for 2 frames\n",
            "bottle detected for 4 frames\n",
            "cigarette detected for 1 frames\n",
            "bottle detected for 3 frames\n",
            "bottle detected for 1 frames\n",
            "Total duration of bottle: 2.30 seconds\n",
            "Total duration of cigarette: 0.13 seconds\n",
            "Total duration of phone: 0.73 seconds\n",
            "Total duration of smoke: 0.00 seconds\n",
            "Total duration of vape: 0.00 seconds\n",
            "Durations for each object:\n",
            "bottle: 2.30 seconds\n",
            "cigarette: 0.13 seconds\n",
            "phone: 0.73 seconds\n",
            "smoke: 0.00 seconds\n",
            "vape: 0.00 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INI DIPAKAI UNTUK MENJADIKAN PROCESSED_FRAMES DIJADIIN 1 VIDEO\n",
        "\n",
        "# nama file output video dan pathnya\n",
        "output_video_path = '/content/output_video.mp4'\n",
        "\n",
        "# ukuran dari salah satu frame\n",
        "height, width, _ = processed_frames[0].shape\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Format codec untuk file MP4\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "# setiap frame yang telah diproses \"ditulis\" ke dalam file video\n",
        "for frame in processed_frames:\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()\n",
        "\n",
        "print(f'Video berhasil disimpan di: {output_video_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQxWhPO4fGCr",
        "outputId": "090b457e-91ee-49d1-9bb6-50dc302de4df"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video berhasil disimpan di: /content/output_video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INXSRSGz04a2",
        "outputId": "7b7ceb3f-b6f6-4303-cdfd-9b876b24557f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 🚀 2024-6-8 Python-3.10.12 torch-2.3.0+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phone detected for 0.67 seconds\n",
            "phone detected for 0.03 seconds\n",
            "phone detected for 0.03 seconds\n",
            "bottle detected for 0.03 seconds\n",
            "bottle detected for 0.13 seconds\n",
            "bottle detected for 0.03 seconds\n",
            "bottle detected for 0.34 seconds\n",
            "bottle detected for 0.11 seconds\n",
            "cigarette detected for 0.03 seconds\n",
            "bottle detected for 0.43 seconds\n",
            "bottle detected for 0.06 seconds\n",
            "bottle detected for 0.03 seconds\n",
            "cigarette detected for 0.03 seconds\n",
            "cigarette detected for 0.03 seconds\n",
            "bottle detected for 0.67 seconds\n",
            "bottle detected for 0.06 seconds\n",
            "bottle detected for 0.03 seconds\n",
            "bottle detected for 0.06 seconds\n",
            "bottle detected for 0.13 seconds\n",
            "cigarette detected for 0.03 seconds\n",
            "bottle detected for 0.03 seconds\n",
            "bottle detected for 0.18 seconds\n",
            "Total duration of bottle: 2.34 seconds\n",
            "Total duration of cigarette: 0.13 seconds\n",
            "Total duration of phone: 0.74 seconds\n",
            "Total duration of smoke: 0.00 seconds\n",
            "Total duration of vape: 0.00 seconds\n",
            "Output video saved to output_video.mp4\n",
            "Durations for each object:\n",
            "bottle: 2.34 seconds\n",
            "cigarette: 0.13 seconds\n",
            "phone: 0.74 seconds\n",
            "smoke: 0.00 seconds\n",
            "vape: 0.00 seconds\n"
          ]
        }
      ],
      "source": [
        "#INI INPUTNYA VIDEO LANGSUNG\n",
        "\n",
        "import torch\n",
        "import cv2\n",
        "\n",
        "def detect_objects_in_video(model_path, video_path, output_video_path, object_labels):\n",
        "    # Load YOLOv5 model\n",
        "    model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path, force_reload=True)\n",
        "\n",
        "    # Open video file\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get video properties\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Define video writer\n",
        "    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "    # Variables to track detected object and its duration\n",
        "    detected_object = None\n",
        "    start_time = None\n",
        "    total_duration = {label: 0 for label in object_labels}\n",
        "\n",
        "    # Process each frame of the video\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Perform object detection on the frame\n",
        "        results = model(frame)\n",
        "\n",
        "        # Flags to indicate if any object is detected in the current frame\n",
        "        object_detected = {label: False for label in object_labels}\n",
        "\n",
        "        # Draw bounding boxes on the frame\n",
        "        for detection in results.xyxy[0]:\n",
        "            x1, y1, x2, y2, confidence, class_idx = detection\n",
        "            label = model.names[int(class_idx)]\n",
        "\n",
        "            # Convert coordinates to integers\n",
        "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "\n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "            # Add label and confidence score\n",
        "            text = f'{label}: {confidence:.2f}'\n",
        "            cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "            # Track detected objects\n",
        "            if label in object_labels:\n",
        "                object_detected[label] = True\n",
        "\n",
        "        # Update detected objects and their durations\n",
        "        for label in object_labels:\n",
        "            if object_detected[label]:\n",
        "                if detected_object != label:\n",
        "                    detected_object = label\n",
        "                    start_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000  # Convert milliseconds to seconds\n",
        "            else:\n",
        "                if detected_object == label:\n",
        "                    end_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000  # Convert milliseconds to seconds\n",
        "                    duration = end_time - start_time\n",
        "                    total_duration[label] += duration\n",
        "                    print(f'{label} detected for {duration:.2f} seconds')\n",
        "                    detected_object = None\n",
        "\n",
        "        # Write output frame to video writer\n",
        "        out.write(frame)\n",
        "\n",
        "    # Release video capture and writer\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    # Print total duration of the detected objects\n",
        "    for label, duration in total_duration.items():\n",
        "        print(f'Total duration of {label}: {duration:.2f} seconds')\n",
        "\n",
        "    return output_video_path, total_duration\n",
        "\n",
        "# Contoh penggunaan fungsi\n",
        "model_path = '/content/weightsbest (1).pt'\n",
        "video_path = '/content/WIN_20240603_15_00_18_Pro.mp4'\n",
        "output_video_path = 'output_video.mp4'\n",
        "object_labels = ['bottle', 'cigarette', 'phone', 'smoke', 'vape']\n",
        "\n",
        "output_video, durations = detect_objects_in_video(model_path, video_path, output_video_path, object_labels)\n",
        "\n",
        "print(f'Output video saved to {output_video}')\n",
        "print('Durations for each object:')\n",
        "for label, duration in durations.items():\n",
        "    print(f'{label}: {duration:.2f} seconds')\n"
      ]
    }
  ]
}